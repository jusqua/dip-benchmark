\section{Fundamentação Teórica}

Nesta seção, serão apresentados conceitos e ferramentas que foram utilizadas no desenvolvimento da pesquisa. Serão abordados conceitos de paralelismo, arquiteturas heterogêneas, operadores de processamento de imagens, modelos de programação paralela, em específico CUDA e SYCL, e brevemente sobre frameworks e bibliotecas relevantes para o tema. Esses conceitos mostram o estado da arte na área de computação paralela e processamento de imagens, fornecendo a base teórica necessária para compreender o desenvolvimento do trabalho.

\subsection{Processamento de imagens digitais}

Nesta subseção, serão apresentados conceitos básicos sobre imagens digitais, operações pontuais e matriciais, operações lineares e não-lineares, operações ponto-a-ponto e de janela, e operações morfológicas. Esses conceitos são fundamentais para entender as técnicas e algoritmos utilizados no processamento de imagens.

\subsubsection{Imagens digitais}

Uma imagem digital é uma representação bidimensional de uma cena ou objeto, composta por uma matriz de píxeis (do inglês, \textit{picture elements}). Cada píxel contém informações sobre cor e intensidade, que podem ser representadas em diferentes formatos, como RGB (vermelho, verde, azul), RGBA (RGB com fator de transparência alfa) ou escala de cinza~\cite{gonzalez17}.

Imagens armazenam informações visuais que podem ser processadas e analisadas por funções matemáticas por computadores para, por exemplo, melhorar a nitidez, extrair características ou preparar para análise posterior.

Imagens com 2D podem ser representadas como uma matriz \(I\) de tamanho \(M \times N\), onde \(M\) é o número de linhas (altura) e \(N\) é o número de colunas (largura). Cada elemento \(I(i,j)\) da matriz representa o valor do píxel na posição \((i,j)\). Em imagens em escala de cinza, esse valor é um número entre 0 (preto) e 1 (branco). Em imagens coloridas, cada píxel pode ser representado por três ou quatro valores correspondentes aos canais RGB e RGBA, respectivamente~\cite{gonzalez17}.

\subsubsection{Operações pontuais e matriciais}

Uma operação é dita pontual quando processa os dados de cada píxel da imagem resultante sem depender de dados vizinhos, já uma operação é dita matricial quando processa os dados de cada píxel da imagem utilizando todo o escopo da imagem aplicando transformações lineares~\cite{gonzalez17}.
\noindent O produto pontual das imagens (denotado pelo símbolo $\odot$ ou $\otimes$) é formado multiplicado os elementos homólogos (de mesmo índice):
\[
	\begin{bmatrix}
		a_{11} & a_{12} \\
		a_{21} & a_{22} \\
	\end{bmatrix}
	\odot
	\begin{bmatrix}
		b_{11} & b_{12} \\
		b_{21} & b_{22} \\
	\end{bmatrix}
	=
	\begin{bmatrix}
		a_{11}b_{11} & a_{12}b_{12} \\
		a_{21}b_{21} & a_{22}b_{22} \\
	\end{bmatrix}
\]
\noindent O produto matricial das imagens é formado usando a regra da multiplicação de matrizes:
\[
	\begin{bmatrix}
		a_{11} & a_{12} \\
		a_{21} & a_{22} \\
	\end{bmatrix}
	\begin{bmatrix}
		b_{11} & b_{12} \\
		b_{21} & b_{22} \\
	\end{bmatrix}
	=
	\begin{bmatrix}
		a_{11}b_{11}+a_{12}b_{21} & a_{11}b_{12}+a_{12}b_{22} \\
		a_{21}b_{11}+a_{22}b_{21} & a_{21}b_{12}+a_{22}b_{22} \\
	\end{bmatrix}
\]

Produto matricial é comumente utilizado em operações de transformação geométrica, como rotação, escala e translação de imagens que é um ponto de foco para computação gráfica~\cite{shirley15}. Logo, quando uma operação ser apresentada nesse trabalho será considerado exclusivamente uma operação pontual, a menos que seja explicitamente declarado como uma operação matricial.

\subsubsection{Operações lineares e não-lineares}

Um operador \(L\) que atua sobre imagens é dito linear se satisfaz o princípio da superposição, isto é, se para quaisquer imagens \(I_1, I_2\) e quaisquer escalares \(a, b \in \mathbb{R}\) vale:
\begin{enumerate}
	\item \textbf{Aditividade:} \(L(I_1 + I_2) = L(I_1) + L(I_2)\).
	\item \textbf{Homogeneidade:} \(L(a I_1) = a\,L(I_1)\).
\end{enumerate}
Em consequência, para combinações lineares genéricas tem-se \(L(a\,I_1 + b\,I_2) = a\,L(I_1) + b\,L(I_2)\). Quaisquer operadores que não satisfazem essas propriedades são chamados não-lineares~\cite{gonzalez17}.

\noindent Um exemplo de operador linear é a escala de cinza, que pode ser representada como uma combinação linear dos canais RGB:
\begin{equation}
	\label{eq:grayscale}
	I_{out}(i,j) = G(I(i,j)) = 0.299 R + 0.587 G + 0.114 B
\end{equation}

\noindent Um exemplo de operador não-linear é a limiarização, que define um valor de corte \(T\) para segmentar a imagem em duas classes utilizando os valores dos píxeis:
\begin{equation}
	\label{eq:thresholding}
	I_{out}(i,j) = T(I(i,j)) =
	\begin{cases}
		1, & I(i,j) \geq T \\
		0, & I(i,j) < T
	\end{cases}
\end{equation}

\subsubsection{Operações ponto-a-ponto e de janela}

Um operador é dito de ponto-a-ponto quando altera cada píxel da própria imagem por meio de um valor de referência para produzir a imagem resultante~\cite{gonzalez17}. Sendo assim, cada píxel da imagem resultante depende exclusivamente do valor do píxel correspondente na imagem original. Considerando uma função de transformação \(T(z)\) tem como exemplo a operação complemento ou inversão de cores, que pode ser definida como:
\begin{equation}
	\label{eq:inversion}
	I_{out}(i,j) = T(I_{in}(i,j)) = 1 - I_{in}(i,j)
\end{equation}

Um operador é dito de janela quando processa uma imagem considerando a vizinhança dos píxeis por meio de uma máscara ou \textit{kernel} representado por uma matriz aplicado sobre a imagem original para produzir a imagem resultante. Com isso, cada píxel da imagem resultante depende dos valores dos píxeis vizinhos na imagem original. Considerando uma máscara \(K\) de tamanho \(m \times n\), a operação de convolução é um exemplo de operador de janela, definida como:
\begin{equation}
	\label{eq:convolution}
	I_{out}(i,j) = \sum_{u=-\lfloor m/2 \rfloor}^{\lfloor m/2 \rfloor} \sum_{v=-\lfloor n/2 \rfloor}^{\lfloor n/2 \rfloor} K(u,v) \cdot I_{in}(i+u,j+v)
\end{equation}

\subsubsection{Operações morfológicas}

Operações morfológicas constituem uma família distinta de transformações que exploram a forma e a estrutura de objetos na imagem por meio de um elemento estruturante \(B\). Em imagens binárias, uma imagem pode ser vista como um conjunto \(A \subset \mathbb{Z}^2\) dos pontos (píxeis) com valor 1. As duas operações fundamentais são erosão e dilatação, definidas em termos de teoria dos conjuntos como:
\begin{equation}
	\label{eq:erosion}
	A \ominus B = \{ z \in \mathbb{Z}^2 \mid B_z \subseteq A \},
\end{equation}
\begin{equation}
	\label{eq:dilation}
	A \oplus B = \{ z \in \mathbb{Z}^2 \mid \hat{B}_z \cap A \neq \emptyset \},
\end{equation}

onde \(B_z\) denota a translação do elemento estruturante \(B\) pela posição \(z\) e \(\hat{B}\) é a reflexão de \(B\). Intuitivamente, a erosão encolhe objetos e remove pequenos artefatos, enquanto a dilatação expande objetos e preenche lacunas.

A escolha do elemento estruturante — sua forma (retangular, disco, cruz, etc.) e seu tamanho — determina quais características morfológicas são preservadas ou removidas~\cite{gonzalez17}.

\subsection{Arquiteturas de computadores}

Nessa subseção, serão apresentados conceitos básicos sobre arquiteturas de computadores, componentes importantes, sistemas operacionais e programação paralela e concorrente. Não entraremos em detalhes técnicos profundos, mas forneceremos uma visão geral suficiente para entender os tópicos subsequentes relacionados à programação paralela em GPUs.

\subsubsection{Componentes importantes}

A CPU é responsável por executar instruções de programas. Em arquiteturas com um único núcleo, a execução é essencialmente sequencial; arquiteturas com múltiplos núcleos permitem execução física simultânea de instruções. Essas características de hardware definem capacidades e limitações para paralelização de tarefas~\cite{ArpaciDusseau23,pacheco11}.

A GPU é um dispositivo especializado em calcular operações matemáticas em paralelo. Originalmente foram projetadas para auxiliar a CPU no processamento de gráficos, imagens, vídeos, jogos eletrônicos e entre outras aplicações~\cite{gonzalez17}.

\subsubsection{Sistemas operacionais}

O sistema operacional gerencia a execução de processos e \textit{threads} mediante políticas de escalonamento e troca de contexto, permitindo que múltiplos processos aparentem ser executados simultaneamente mesmo em hardware com poucos núcleos. Esse comportamento é comumente denominado concorrência e é essencial para responsividade e compartilhamento de recursos~\cite{ArpaciDusseau23}.

Um processo é uma instância de um programa em execução com seu próprio espaço de endereçamento. \textit{Threads} são unidades de execução num processo que compartilham memória e recursos, o que facilita a comunicação, mas exige mecanismos de sincronização como travas e barreiras para evitar condições de corrida~\cite{ArpaciDusseau23}.

Enquanto uma CPU contêm núcleos de processamento mais complexos que operam instruções sequencialmente, uma GPU tem uma arquitetura altamente paralelizável \textit{Single Instruction, Multiple Data} (SIMD) com até dezenas de milhares de núcleos de processamento mais simples~\cite{nickolls2008}. Um exemplo é demonstrado na \Cref{fig:gpu-cpu-comparation}, onde a área de silício dedicada ao processamento em uma GPU é significativamente maior do que em uma CPU, refletindo sua capacidade de paralelismo massivo~\cite{stallings15computer}.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.8\linewidth]{images/gpu-cpu-comparation.png}
	\caption{Comparação da Área de Silício/Dedicação de Transistores entre CPU e GPU. Imagem adaptada de~\cite{stallings15computer}.}
	\label{fig:gpu-cpu-comparation}
\end{figure}

\subsubsection{Programação paralela e concorrente}

De forma simples, o principal objetivo da programação paralela é computar algo mais rapidamente. Um processo é dito paralelo quando uma tarefa é dividida em pequenas partes executadas simultaneamente com o intuito de acelerar a execução desta tarefa~\cite{ArpaciDusseau23,james23dpcpp}. A programação paralela é especialmente útil para tarefas que envolvem grandes volumes de dados ou cálculos complexos, onde a divisão do trabalho pode levar a melhorias significativas no desempenho.

Concorrência descreve a gestão de múltiplas tarefas que progridem simultaneamente ao nível lógico; paralelismo refere-se à execução física simultânea de várias tarefas permitidas pela unidade de processamento. O número de \textit{threads} que pode ser escalonado de forma eficiente depende tanto do sistema operacional quanto da arquitetura de hardware. Exceder esses recursos faz com que as \textit{threads} concorram por CPU, memória e cache, aumentando trocas de contexto e, em muitos casos, degradando o desempenho~\cite{ArpaciDusseau23,stallings15computer}.

Dois padrões recorrentes são o \textit{data parallelism} e o \textit{task parallelism}. Em \textit{data parallelism} uma única tarefa é aplicada para todas as \textit{threads}, já em \textit{task parallelism} as \textit{threads} são distribuídas para múltiplas tarefas~\cite{pacheco11}. Esses modelos orientam a escolha de algoritmos e frameworks de programação paralela.
Será dada ênfase em \textit{data parallelism}, pois é o modelo mais adequado para o processamento de imagens, sendo o foco deste trabalho.

\subsubsection{GPGPU}

GPUs passaram a ser usadas para computação de propósito geral (GPGPU) em aplicações com algoritmos altamente paralelizáveis~\cite{stallings15computer,james23dpcpp}, como processamento de imagens e aprendizados de máquina. Embora GPUs entreguem alta transferência e processamento de dados, há custos associados: latência de transferência de dados entre CPU e GPU, custos de gerenciamento e aumento de complexidade de programação.

Para ser possível produzir programas utilizando GPU, tanto o dispositivo deve suportar as operações presentes nas especificações modelo específico quanto o controlador do sistema operacional deve disponibilizar a API para que o desenvolvedor possar fazer uso~\cite{nickolls2008}.

O modelo mais utilizado para programação em GPU é o \textit{Single Instructions, Multiple Threads} (SIMT), um subconjunto do modelo SIMD utilizando múltiplas \textit{threads} do dispositivo para operar uma instrução única concorrentemente. Cada \textit{thread} é responsável por um subconjunto dos dados, permitindo que milhares de \textit{threads} sejam executadas em paralelo. A arquitetura SIMT é eficiente para operações que podem ser divididas em muitas tarefas independentes, como processamento de imagens, onde cada píxel pode ser processado separadamente~\cite{nickolls2008,stallings15computer}.

\subsection{Tecnologias de programação paralela}

Nesta subseção, serão apresentadas as principais tecnologias e modelos de programação para computação paralela em GPUs que serão postos a prova. Especificamente, abordaremos CUDA, OpenCL e SYCL, que são amplamente utilizados no desenvolvimento de aplicações de alto desempenho.

\subsubsection{CUDA}

CUDA (\textit{Compute Unified Device Architecture}) é uma plataforma de programação paralela e um modelo de programação criado pela NVIDIA em 2006~\cite{nickolls2008} o que permite que desenvolvedores utilizem GPUs da NVIDIA para computação de propósito geral, expondo diretamente a arquitetura paralela do hardware via extensões da linguagem C/C++.

No modelo CUDA, o código executado na GPU é denominado \textit{kernel}, que é uma função executada em paralelo por milhares de \textit{threads}. As \textit{threads} são organizadas hierarquicamente em \textit{blocos} e \textit{grids}, permitindo que o programador expresse tanto paralelismo em dados quanto em tarefas. Cada \textit{thread} possui um identificador único que pode ser usado para determinar qual porção dos dados ela deve processar~\cite{nickolls2008}.

O modelo de memória CUDA é composto por diferentes tipos de memória com características distintas de latência e largura de banda: memória global (acessível por todas as \textit{threads}, mas com alta latência), memória compartilhada (rápida, mas limitada a um bloco de \textit{threads}), registradores (privados a cada \textit{thread}) e memória constante.

Um exemplo clássico de aplicação CUDA é a soma vetorial, onde dois vetores \(A\) e \(B\) de tamanho \(N\) são somados elemento a elemento para produzir um vetor \(C\):
\begin{lstlisting}[caption={Exemplo de soma vetorial em CUDA.}, label={lst:cuda-vector-add}]
__global__ void vectorAdd(float* A, float* B, float* C, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        C[idx] = A[idx] + B[idx];
    }
}
\end{lstlisting}

Neste exemplo, cada \textit{thread} calcula a soma de um único elemento dos vetores de entrada. A expressão \texttt{blockIdx.x * blockDim.x + threadIdx.x} determina o índice global da \textit{thread}, garantindo que cada elemento seja processado exatamente uma vez.

\subsubsection{OpenCL}

OpenCL (\textit{Open Computing Language}) é um padrão aberto e livre de \textit{royalties} mantido pelo Khronos Group para programação paralela heterogênea~\cite{stone2010opencl}. Lançado em 2009, OpenCL foi projetado para ser portável entre diferentes tipos de processadores, incluindo CPUs, GPUs, FPGAs e outros aceleradores, permitindo que o mesmo código seja executado em hardware de diferentes fabricantes~\cite{opencl2025}.

Diferentemente do CUDA, específico para GPUs NVIDIA, OpenCL adota uma abordagem agnóstica de plataforma. O modelo de programação OpenCL separa claramente o código do \textit{host} (CPU) do código do dispositivo (\textit{kernel}), compilado em tempo de execução. Isso proporciona flexibilidade, mas pode introduzir complexidade adicional no desenvolvimento~\cite{stone2010opencl}.

O modelo de memória OpenCL define quatro regiões distintas: memória global, memória constante, memória local (equivalente à memória compartilhada do CUDA) e memória privada. O modelo de execução organiza \textit{work-items} (equivalente a \textit{threads} no CUDA) em \textit{work-groups} (equivalente a blocos)~\cite{opencl2025}.

Um exemplo equivalente de soma vetorial em OpenCL seria:
\begin{lstlisting}[caption={Exemplo de soma vetorial em OpenCL.}, label={lst:opencl-vector-add}]
__kernel void vectorAdd(__global float* A, __global float* B, __global float* C, int N) {
    int idx = get_global_id(0);
    if (idx < N) {
        C[idx] = A[idx] + B[idx];
    }
}
\end{lstlisting}

O qualificador \texttt{\_\_global} indica que os ponteiros apontam para memória global do dispositivo, e \texttt{get\_global\_id(0)} retorna o identificador global do \textit{work-item} na dimensão 0.

\subsubsection{SYCL}

SYCL é um padrão de programação paralela em C++ de alto nível, também mantido pelo Khronos Group. Lançado inicialmente em 2014 e atualizado significativamente na versão 2020, SYCL constrói sobre o OpenCL fornecendo uma interface moderna em C++ puro, sem necessidade de extensões de linguagem ou sintaxe especial para \textit{kernels}.

O principal diferencial do SYCL é sua abordagem de \textit{single-source}, onde o código do \textit{host} e do dispositivo residem no mesmo código-fonte e utilizam C++. Isso permite o uso de recursos da linguagem como \textit{templates}, \textit{lambdas} e inferência de tipos, tornando o código mais expressivo e menos propenso a erros~\cite{james23dpcpp}.

SYCL também promove portabilidade através do conceito de \textit{backends}, permitindo que o mesmo código seja executado em diferentes tipos de hardware (GPUs NVIDIA, AMD, Intel, CPUs, FPGAs) sem modificações. Implementações populares incluem DPC++ (Data Parallel C++, da Intel) e AdaptiveCpp~\cite{james23dpcpp,acpp}.

O modelo de execução SYCL utiliza filas (\texttt{queue}) para submeter trabalho aos dispositivos, e define \textit{kernels} usando expressões lambda ou \textit{functors}. O modelo de memória abstrai as diferentes regiões mediante \textit{buffers} e \textit{accessors}, gerenciando automaticamente transferências de dados e sincronização.

Exemplo de soma vetorial em SYCL com \textit{buffers}:

\begin{lstlisting}[caption={Exemplo de soma vetorial em SYCL utilizando \textit{buffers}.}, label={lst:sycl-buffer-vector-add}]
queue q;

buffer<float> bufA(A, N);
buffer<float> bufB(B, N);
buffer<float> bufC(C, N);

q.submit([&](handler &h) {
    accessor accA(bufA, h, read_only);
    accessor accB(bufB, h, read_only);
    accessor accC(bufC, h, write_only);

    h.parallel_for(range<1>(N), [=](id<1> idx) {
        accC[idx] = accA[idx] + accB[idx];
    });
});
\end{lstlisting}

Neste exemplo, os \textit{buffers} encapsulam os dados e os \textit{accessors} declaram como cada \textit{kernel} acessa a memória. O método \texttt{parallel\_for} expressa o paralelismo de dados, e uma expressão lambda define o corpo do \textit{kernel}.

Também é suportado uso de \textit{Unified Shared Memory} (USM) para acesso direto à memória compartilhada entre host e dispositivo utilizando a sintaxe de ponteiros com gerenciamento manual de memória~\cite{james23dpcpp}.

Exemplo de soma vetorial em SYCL com USM:

\begin{lstlisting}[caption={Exemplo de soma vetorial em SYCL utilizando USM.}, label={lst:sycl-usm-vector-add}]
queue q;

size_t size = N * sizeof(float);
float* memA = malloc_device<float>(size);
float* memB = malloc_device<float>(size);
float* memC = malloc_device<float>(size);

q.memcpy(memA, A, size).wait();
q.memcpy(memB, B, size).wait();

q.parallel_for(range<1>(N), [=](id<1> idx) {
    memC[idx] = memA[idx] + memB[idx];
}).wait();

q.memcpy(C, memC, size).wait();
\end{lstlisting}
